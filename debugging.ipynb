{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## debugging the py files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "'''\n",
    "input:\n",
    "    - data_file: json data file path\n",
    "    - speech_type: FED or ECB, or both (needs to be implemented)\n",
    "    - task_type: classif or reg, process the data of the two tasks separatively\n",
    "    - val_size: validation set size ratio\n",
    "\n",
    "1. turn each speech into a list of words (for now it's just for summarization, so no need for max_len)\n",
    "2. get rid of strange tokens (needs to be implemented)\n",
    "\n",
    "returns:\n",
    "    - X_train: a list of word_list for training\n",
    "    - X_val: a list of word_list for validation\n",
    "    - y_train: label (classification label or regression price) for training\n",
    "    - y_val: label (classification label or regression price) for validation\n",
    "\n",
    "'''\n",
    "def read_data(data_file, speech_type=['ECB', 'FED'], task_type='classif', val_size=0.2):\n",
    "    with open(data_file, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "    \n",
    "    #data = json.loads(data)\n",
    "    \n",
    "    spch_list = []\n",
    "    label_list = []\n",
    "    for data_dict in data:\n",
    "        label_list.append(data_dict['target_' + task_type])\n",
    "        \n",
    "        s = data_dict['speech'][-1]\n",
    "        if s[speech_type[0]]:\n",
    "            l = s[speech_type[0]][0].strip()\n",
    "        else:\n",
    "            l = s[speech_type[1]][0].strip()\n",
    "        #words = l.split(' ')\n",
    "        spch_list.append(l)\n",
    "    \n",
    "    print('[Info] Get {} instances from {}'.format(len(spch_list), data_file))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(spch_list, label_list, test_size=val_size, random_state=42)\n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=val_size, random_state=42)\n",
    "\n",
    "    train_ds = pd.DataFrame(list(zip(X_train, y_train)),\n",
    "               columns =['text', 'label'])\n",
    "    \n",
    "    dev_ds = pd.DataFrame(list(zip(X_dev, y_dev)),\n",
    "               columns =['text', 'label'])\n",
    "    \n",
    "    test_ds = pd.DataFrame(list(zip(X_test, y_test)),\n",
    "               columns =['text', 'label'])\n",
    "\n",
    "    return train_ds, dev_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Get 1254 instances from summary_text.json\n",
      "[Info] Convert training word instances into sequences of word index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (557 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Convert validation word instances into sequences of word index.\n",
      "[Info] Dumping the processed data to pickle file data_processed\n",
      "[Info] Finish.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# get training set and validation set\n",
    "X_train, X__val, y_train, y_val = read_data(\n",
    "    'summary_text.json')\n",
    "\n",
    "# Build vocabulary\n",
    "#if opt.vocab:\n",
    "#    predefined_data = torch.load(opt.vocab)\n",
    "#    assert 'dict' in predefined_data\n",
    "\n",
    "#    print('[Info] Pre-defined vocabulary found.')\n",
    "#    src_word2idx = predefined_data['dict']['src']\n",
    "#    tgt_word2idx = predefined_data['dict']['tgt']\n",
    "#else:\n",
    "\n",
    "\n",
    "\n",
    "# word to index\n",
    "print('[Info] Convert training word instances into sequences of word index.')\n",
    "\n",
    "X_train_insts = [tokenizer(i, return_tensors='pt') for i in X_train]\n",
    "\n",
    "print('[Info] Convert validation word instances into sequences of word index.')\n",
    "X_val_insts = [tokenizer(i, return_tensors='pt') for i in X__val]\n",
    "\n",
    "data = {\n",
    "    #'settings': opt,\n",
    "    'train': {\n",
    "        'X': X_train_insts,\n",
    "        'y': y_train},\n",
    "    'valid': {\n",
    "        'X': X_val_insts,\n",
    "        'y': y_val}}\n",
    "\n",
    "print('[Info] Dumping the processed data to pickle file', 'data_processed')\n",
    "#torch.save(data, opt.save_data)\n",
    "print('[Info] Finish.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_insts[0]['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 3930,\n",
       " 4254,\n",
       " 1997,\n",
       " 8332,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 2006,\n",
       " 1996,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 1998,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 12194,\n",
       " 3343,\n",
       " 5656,\n",
       " 1999,\n",
       " 2204,\n",
       " 1998,\n",
       " 2919,\n",
       " 100,\n",
       " 8220,\n",
       " 2013,\n",
       " 1996,\n",
       " 3522,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 1004,\n",
       " 100,\n",
       " 1004,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 1997,\n",
       " 100,\n",
       " 100,\n",
       " 100,\n",
       " 1998,\n",
       " 100,\n",
       " 100,\n",
       " 2019,\n",
       " 3623,\n",
       " 1999,\n",
       " 14338,\n",
       " 1998,\n",
       " 1037,\n",
       " 9963,\n",
       " 1997,\n",
       " 4722,\n",
       " 5157,\n",
       " 2875,\n",
       " 27143,\n",
       " 2550,\n",
       " 100,\n",
       " 20242,\n",
       " 5816,\n",
       " 3976,\n",
       " 100,\n",
       " 100,\n",
       " 100]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_insts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6041666666666666, 1.0, 0.3076923076923077, 0.5855855855855856, 0.3055555555555556, 1.0, 1.0, 0.2867132867132867, 0.7411764705882353, 0.6304347826086957, 1.0, 1.0, 0.24761904761904763, 0.0, 0.6666666666666666, 0.9, 0.22916666666666666, 1.0, 0.2422680412371134, 0.14545454545454545, 0.3364485981308411, 0.0, 0.4845360824742268, 0.16304347826086957, 0.1282051282051282, 0.22105263157894736, 0.168141592920354, 1.0, 0.3253968253968254, 0.2077922077922078, 1.0, 0.24060150375939848, 1.0, 0.8076923076923077, 0.1711229946524064, 0.2840909090909091, 0.1956521739130435, 0.27586206896551724, 0.18681318681318682, 0.0, 0.21604938271604937, 0.24242424242424243, 0.18548387096774194, 0.0, 0.2677165354330709, 0.14285714285714285, 0.23076923076923078, 0.26277372262773724, 0.2328767123287671, 0.27485380116959063, 1.0, 0.18627450980392157, 1.0, 0.16666666666666666, 1.0, 0.22608695652173913, 0.23076923076923078, 0.28, 0.2782608695652174, 0.5081081081081081, 0.0, 0.2288135593220339, 1.0, 0.26605504587155965, 1.0, 0.0, 0.21428571428571427, 1.0, 1.0, 1.0, 1.0, 0.13513513513513514, 0.23140495867768596, 1.0, 0.21311475409836064, 0.8636363636363636, 1.0, 0.20105820105820105, 1.0, 1.0, 0.31932773109243695, 1.0, 0.18110236220472442, 0.19607843137254902, 0.22330097087378642, 0.0, 0.0, 0.18404907975460122, 0.24647887323943662, 0.17647058823529413, 0.21311475409836064, 1.0, 0.40601503759398494, 1.0, 1.0, 0.21686746987951808, 0.18877551020408162, 0.53125, 0.0, 0.23333333333333334, 1.0, 0.19696969696969696, 0.18461538461538463, 0.2682926829268293, 0.7761194029850746, 0.175, 1.0, 0.22627737226277372, 1.0, 0.18181818181818182, 0.2302158273381295, 0.18548387096774194, 0.25, 0.18699186991869918, 0.10077519379844961, 0.0, 0.1826086956521739, 0.415929203539823, 1.0, 0.23214285714285715, 0.15838509316770186, 1.0, 0.24778761061946902, 1.0, 1.0, 0.1917808219178082, 1.0, 0.5526315789473685, 0.7452830188679245, 0.17647058823529413, 0.0, 1.0, 0.1897810218978102, 0.14173228346456693, 0.1509433962264151, 0.1927710843373494, 0.21348314606741572, 0.5743243243243243, 0.2441860465116279, 0.23783783783783785, 0.0, 0.24822695035460993, 0.13861386138613863, 0.24603174603174602, 0.16115702479338842, 0.6907216494845361, 1.0, 0.2153846153846154, 0.1320754716981132, 0.39814814814814814, 0.2824427480916031, 0.11797752808988764, 0.20634920634920634, 0.2421875, 0.19289340101522842, 0.17446808510638298, 1.0, 0.1565217391304348, 0.2988505747126437, 0.20353982300884957, 0.0, 1.0, 1.0, 0.7345132743362832, 0.21428571428571427, 0.2032520325203252, 0.15827338129496402, 1.0, 0.25773195876288657, 0.1292517006802721, 0.0, 1.0, 0.0, 0.42452830188679247, 0.1827956989247312, 1.0, 0.2864583333333333, 0.16822429906542055, 0.13740458015267176, 0.18490566037735848, 0.6029411764705882, 0.16049382716049382, 0.15748031496062992, 0.21511627906976744, 1.0, 0.2111111111111111, 0.20863309352517986, 0.20634920634920634, 1.0, 0.171875, 0.18584070796460178, 0.14736842105263157, 0.1958041958041958, 0.5094339622641509, 0.24528301886792453, 0.14414414414414414, 0.22839506172839505, 0.1941747572815534, 0.2523364485981308, 0.14556962025316456, 0.16551724137931034, 0.20945945945945946, 0.36764705882352944, 0.6911764705882353, 0.37349397590361444, 0.2457627118644068, 0.7096774193548387, 0.18823529411764706, 0.20441988950276244, 0.22772277227722773, 0.0, 1.0, 0.3763440860215054, 1.0, 1.0, 0.0, 1.0, 0.0, 0.14678899082568808, 0.1953125, 0.23478260869565218, 0.15384615384615385, 1.0, 1.0, 1.0, 0.26436781609195403, 0.6956521739130435, 0.23529411764705882, 0.5172413793103449, 1.0, 0.15037593984962405, 0.0, 0.11764705882352941, 0.45901639344262296, 1.0, 0.23214285714285715, 0.2403846153846154, 1.0, 0.20555555555555555, 0.2878787878787879, 1.0, 0.0, 0.1510791366906475, 0.2247191011235955, 0.1981981981981982, 0.27722772277227725, 1.0, 1.0, 0.3958333333333333, 0.17647058823529413, 0.1962025316455696, 1.0, 1.0, 0.15126050420168066, 0.15126050420168066, 0.2080536912751678, 0.31343283582089554, 0.23026315789473684, 0.16161616161616163, 0.20238095238095238, 0.7368421052631579, 1.0, 0.22608695652173913, 0.2361111111111111, 1.0, 0.15789473684210525, 0.25471698113207547, 0.22910216718266255, 0.3238095238095238, 0.2, 0.17318435754189945, 1.0, 0.24705882352941178, 0.6923076923076923, 1.0, 0.14634146341463414, 1.0, 0.0, 0.17073170731707318, 1.0, 0.6610169491525424, 0.26282051282051283, 0.14285714285714285, 0.3411764705882353, 0.2248062015503876, 1.0, 0.32653061224489793, 0.18243243243243243, 0.16778523489932887, 0.17006802721088435, 0.23469387755102042, 1.0, 0.3113207547169811, 0.1875, 0.21621621621621623, 1.0, 0.19827586206896552, 0.7444444444444445, 0.1956521739130435, 0.5290697674418605, 1.0, 0.19576719576719576, 0.2602739726027397, 0.28378378378378377, 0.1891891891891892, 0.18627450980392157, 0.25757575757575757, 1.0, 0.7623762376237624, 0.28865979381443296, 0.2159090909090909, 0.3888888888888889, 0.18888888888888888, 0.18947368421052632, 0.2072072072072072, 0.29213483146067415, 0.19672131147540983, 0.0, 1.0, 1.0, 0.2, 0.18867924528301888, 0.19463087248322147, 0.3115942028985507, 0.0, 0.23469387755102042, 0.2222222222222222, 0.20161290322580644, 0.5555555555555556, 1.0, 0.15555555555555556, 0.2571428571428571, 1.0, 0.18548387096774194, 0.7903225806451613, 0.25, 1.0, 0.3700787401574803, 0.0, 0.0, 0.0, 0.18994413407821228, 1.0, 0.2231404958677686, 0.2708333333333333, 0.20408163265306123, 0.211864406779661, 0.19230769230769232, 0.5409836065573771, 1.0, 0.18840579710144928, 0.18128654970760233, 1.0, 1.0, 0.15178571428571427, 1.0, 0.22535211267605634, 1.0, 0.0, 0.19298245614035087, 1.0, 0.3270440251572327, 0.2598870056497175, 0.21238938053097345, 0.17094017094017094, 0.8028169014084507, 1.0, 0.23333333333333334, 0.13588850174216027, 0.2558139534883721, 0.2265625, 0.19078947368421054, 0.2535211267605634, 0.2085889570552147, 1.0, 0.3333333333333333, 0.4845360824742268, 0.0, 0.22105263157894736, 1.0, 0.0, 0.1926605504587156, 1.0, 0.17391304347826086, 0.0, 1.0, 1.0, 1.0, 0.34265734265734266, 0.2222222222222222, 0.2222222222222222, 0.15976331360946747, 0.18620689655172415, 0.18604651162790697, 0.1590909090909091, 0.0, 0.13963963963963963, 0.0, 1.0, 0.16346153846153846, 0.19047619047619047, 1.0, 1.0, 0.34459459459459457, 0.0, 1.0, 0.27419354838709675, 0.7142857142857143, 0.5316455696202531, 0.19827586206896552, 0.0, 0.2011173184357542, 0.24242424242424243, 0.18699186991869918, 0.0, 0.0, 0.22580645161290322, 0.6212121212121212, 0.5875706214689266, 0.15948275862068967, 0.19047619047619047, 0.208955223880597, 0.18627450980392157, 0.0, 0.0, 0.1619047619047619, 0.205607476635514, 0.297029702970297, 0.19428571428571428, 1.0, 0.14516129032258066, 0.16216216216216217, 0.0, 0.2119205298013245, 0.18781725888324874, 1.0, 0.17982456140350878, 0.25333333333333335, 1.0, 1.0, 0.3246753246753247, 1.0, 0.20168067226890757, 0.24102564102564103, 1.0, 1.0, 0.18085106382978725, 0.2158273381294964, 0.20408163265306123, 1.0, 0.6785714285714286, 0.0, 0.4426229508196721, 0.15714285714285714, 0.175, 0.2222222222222222, 0.5576923076923077, 0.2621951219512195, 0.23943661971830985, 1.0, 0.19540229885057472, 1.0, 1.0, 0.1896551724137931, 1.0, 0.0, 1.0, 0.0, 0.26506024096385544, 1.0, 1.0, 0.0, 0.15609756097560976, 0.24822695035460993, 0.1963470319634703, 0.21875, 0.21666666666666667, 0.21551724137931033, 1.0, 0.1925133689839572, 1.0, 0.23140495867768596, 0.20535714285714285, 0.21428571428571427, 1.0, 0.0, 0.16981132075471697, 0.24166666666666667, 0.7338709677419355, 0.1724137931034483, 0.19753086419753085, 0.19473684210526315, 0.6981132075471698, 0.1885245901639344, 1.0, 0.1702127659574468, 0.0, 0.23255813953488372, 0.74, 0.18085106382978725, 0.19827586206896552, 0.14624505928853754, 1.0, 0.21551724137931033, 0.2805755395683453, 0.2558139534883721, 1.0, 1.0, 0.0, 0.23478260869565218, 0.24475524475524477, 0.18435754189944134, 0.2248062015503876, 0.13157894736842105, 1.0, 0.0, 1.0, 0.13636363636363635, 0.0, 0.0, 0.22916666666666666, 0.21621621621621623, 0.2222222222222222, 0.28125, 0.22142857142857142, 0.18604651162790697, 1.0, 0.6224489795918368, 0.1953125, 1.0, 1.0, 0.0, 0.17894736842105263, 0.1810344827586207, 0.0, 0.17857142857142858, 1.0, 1.0, 0.14423076923076922, 1.0, 1.0, 0.21428571428571427, 1.0, 0.22388059701492538, 1.0, 1.0, 0.0, 0.7, 0.0, 0.17699115044247787, 0.19491525423728814, 1.0, 0.14285714285714285, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.26605504587155965, 1.0, 0.0, 0.17391304347826086, 0.18404907975460122, 0.2403846153846154, 0.0, 0.2916666666666667, 0.14583333333333334, 0.17886178861788618, 0.47530864197530864, 1.0, 0.27419354838709675, 0.2815533980582524, 0.2638888888888889, 0.1564245810055866, 0.24087591240875914, 0.2, 0.29545454545454547, 0.7807017543859649, 0.19166666666666668, 0.25, 0.24770642201834864, 0.559322033898305, 1.0, 0.0, 0.15254237288135594, 0.234375, 0.29133858267716534, 0.18269230769230768, 0.20754716981132076, 0.2748091603053435, 1.0, 0.0, 1.0, 0.0, 0.0, 0.23776223776223776, 0.17829457364341086, 1.0, 0.2627118644067797, 0.2, 0.14049586776859505, 0.24571428571428572, 0.18681318681318682, 0.0, 0.17391304347826086, 0.1761006289308176, 0.17105263157894737, 0.2072072072072072, 0.226890756302521, 1.0, 0.0, 0.0, 0.15151515151515152, 0.22857142857142856, 1.0, 1.0, 0.6842105263157895, 0.2066115702479339, 0.1907514450867052, 0.1853932584269663, 0.0, 0.2913907284768212, 0.23125, 0.19701492537313434, 0.3469387755102041, 0.18018018018018017, 0.23853211009174313, 0.20118343195266272, 0.2564102564102564, 0.4824561403508772, 0.17482517482517482, 1.0, 0.13733905579399142, 0.36904761904761907, 0.14285714285714285, 0.2248062015503876, 1.0, 1.0, 1.0, 0.18518518518518517, 0.22388059701492538, 1.0, 1.0, 1.0, 0.2108843537414966, 0.1792452830188679, 0.5666666666666667, 0.18681318681318682, 0.23728813559322035, 0.2483221476510067, 0.0, 0.2564102564102564, 0.21875, 0.1885245901639344, 1.0, 0.20253164556962025, 0.20652173913043478, 1.0, 0.2097902097902098, 0.41414141414141414, 0.39285714285714285, 1.0, 0.25, 1.0, 1.0, 0.3728813559322034, 0.2826086956521739, 0.15384615384615385, 0.21100917431192662, 1.0, 0.20909090909090908, 1.0, 0.23469387755102042, 1.0, 0.24271844660194175, 1.0, 0.22302158273381295, 1.0, 1.0, 0.14388489208633093, 0.20754716981132076, 0.19402985074626866, 0.2184873949579832, 0.17543859649122806, 0.18518518518518517, 0.16279069767441862, 0.1484375, 0.1694915254237288, 0.3523809523809524, 0.0, 0.0, 1.0, 1.0, 0.20408163265306123, 0.2261904761904762, 0.1896551724137931, 0.16939890710382513, 0.13793103448275862, 0.23333333333333334, 0.0, 0.6484018264840182, 0.25675675675675674, 0.1262135922330097, 0.2268041237113402, 0.21904761904761905, 0.14388489208633093, 0.2289156626506024, 0.0, 0.17204301075268819, 1.0, 0.12, 0.29797979797979796, 0.19196428571428573, 0.0, 1.0, 0.21818181818181817, 0.1619047619047619, 1.0, 0.7966101694915254, 1.0, 0.23076923076923078, 0.19480519480519481, 0.1590909090909091, 0.15, 0.19491525423728814, 0.22826086956521738, 0.6627906976744186, 0.23387096774193547, 0.1885245901639344, 0.26744186046511625, 1.0, 0.1702127659574468, 0.33613445378151263, 0.0, 0.31851851851851853, 1.0, 0.5526315789473685, 0.21153846153846154, 0.0, 1.0, 0.18181818181818182, 0.16463414634146342, 0.22727272727272727, 0.0, 0.16964285714285715, 0.18181818181818182, 1.0, 0.17365269461077845, 0.15328467153284672, 0.1919191919191919, 0.15767634854771784, 0.26666666666666666, 1.0, 0.19135802469135801, 0.3076923076923077, 1.0, 1.0, 0.0, 0.37662337662337664, 0.24210526315789474, 1.0, 1.0, 0.1171875, 1.0, 0.2994350282485876, 1.0, 1.0, 1.0, 1.0, 0.0, 0.29850746268656714, 0.20952380952380953, 0.23931623931623933, 0.1875, 0.3695652173913043, 0.7441860465116279, 0.21238938053097345, 0.1978021978021978, 0.1509433962264151, 0.2702702702702703, 1.0, 0.2222222222222222, 0.13076923076923078, 0.2085889570552147, 0.16806722689075632, 1.0, 0.22727272727272727, 1.0, 1.0, 0.1694915254237288, 0.4482758620689655, 1.0, 0.5303030303030303, 1.0, 1.0, 0.2981366459627329, 0.22885572139303484, 0.0, 0.2375, 0.19101123595505617, 0.1935483870967742, 0.5188679245283019, 0.24793388429752067, 1.0, 1.0, 1.0, 0.24528301886792453, 1.0, 0.20437956204379562, 0.18681318681318682, 0.23809523809523808, 0.0, 0.18269230769230768, 0.2595419847328244, 1.0, 0.2231404958677686, 0.0, 1.0, 1.0, 0.1895910780669145, 0.0, 0.21428571428571427, 0.30701754385964913, 0.1797752808988764, 0.20689655172413793, 0.5546218487394958, 1.0, 0.205607476635514, 0.16666666666666666, 0.1476510067114094, 0.0, 0.3017241379310345, 1.0, 0.21585903083700442, 1.0, 1.0, 0.2215568862275449, 1.0, 0.6417910447761194, 1.0, 0.18994413407821228, 0.1504424778761062, 0.14074074074074075, 0.0, 0.16666666666666666, 1.0, 0.13333333333333333, 0.0, 0.20108695652173914, 0.3401360544217687, 0.25547445255474455, 0.21495327102803738, 0.6936936936936937, 1.0, 0.1864406779661017, 1.0, 0.23770491803278687, 0.0, 0.22935779816513763, 0.1469387755102041, 0.22596153846153846, 0.0, 0.7659574468085106, 0.23931623931623933, 1.0, 1.0, 0.17333333333333334, 0.3883495145631068, 0.21138211382113822, 0.3, 1.0, 0.19078947368421054, 0.24113475177304963, 0.20689655172413793, 0.23243243243243245, 0.0, 0.0, 0.15254237288135594, 1.0, 0.13333333333333333, 0.24489795918367346, 0.67, 0.28431372549019607, 0.16, 0.18, 0.7528089887640449, 1.0, 0.18548387096774194, 0.18487394957983194, 0.0, 0.17964071856287425, 0.21875, 0.2711864406779661, 0.15079365079365079, 1.0, 0.1686746987951807, 0.2288135593220339, 0.23157894736842105, 0.35135135135135137, 1.0, 0.28846153846153844, 0.23333333333333334, 0.19642857142857142, 0.1505016722408027, 0.0, 0.23134328358208955, 0.0, 0.2231404958677686, 0.6666666666666666, 0.3068181818181818, 0.15454545454545454, 1.0, 0.0, 0.7256637168141593, 0.18382352941176472, 0.20625, 1.0, 1.0, 0.2826086956521739, 0.19548872180451127, 0.22941176470588234, 0.2920353982300885, 1.0, 0.13716814159292035, 0.4262295081967213, 0.5576923076923077, 0.0, 1.0, 1.0, 0.22077922077922077, 0.0, 0.27522935779816515, 0.20388349514563106, 0.1574074074074074, 0.2265625, 0.2642857142857143, 0.25833333333333336, 0.5891472868217055, 0.17829457364341086, 0.3176470588235294, 0.22941176470588234, 0.2018348623853211, 0.21656050955414013, 0.336734693877551, 0.18493150684931506, 0.275, 1.0, 1.0, 0.1450381679389313, 0.14705882352941177, 0.14606741573033707, 0.18571428571428572, 1.0, 0.7027027027027027, 0.1346153846153846, 0.2, 0.8928571428571429, 1.0, 1.0, 0.20945945945945946, 0.0, 0.0, 0.17714285714285713, 0.2581818181818182, 0.0, 0.1951219512195122, 1.0, 0.6825396825396826, 0.1743119266055046, 0.0, 0.0, 0.0, 1.0, 0.08947368421052632, 0.76, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.19696969696969696, 0.2518518518518518, 0.0, 1.0, 0.35294117647058826, 0.0, 0.20512820512820512, 0.264, 0.22123893805309736, 0.0, 0.26595744680851063, 0.2235294117647059, 1.0, 0.14785992217898833, 0.21951219512195122, 0.19424460431654678, 0.22, 0.20689655172413793, 0.42452830188679247, 0.0, 0.2231404958677686]\n"
     ]
    }
   ],
   "source": [
    "print([sum([j ==  100 for j in i])/len(i) for i in X_train_insts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[UNK]']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = tokenizer.convert_ids_to_tokens([100])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2023, 2003, 1037, 3231,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer('this is a test', return_tensors='pt')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2023, 2003, 1037, 3231, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer('This is a test.')\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, 'data_processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self, src_word2idx, tgt_word2idx,\n",
    "        src_insts=None, tgt_insts=None):\n",
    "\n",
    "        assert src_insts\n",
    "        assert not tgt_insts or (len(src_insts) == len(tgt_insts))\n",
    "\n",
    "        src_idx2word = {idx:word for word, idx in src_word2idx.items()} #字典 key:词汇编号 value:词汇\n",
    "        self._src_word2idx = src_word2idx\n",
    "        self._src_idx2word = src_idx2word\n",
    "        self._src_insts = src_insts\n",
    "\n",
    "        tgt_idx2word = {idx:word for word, idx in tgt_word2idx.items()}\n",
    "        self._tgt_word2idx = tgt_word2idx\n",
    "        self._tgt_idx2word = tgt_idx2word\n",
    "        self._tgt_insts = tgt_insts\n",
    "\n",
    "    @property\n",
    "    def n_insts(self):\n",
    "        ''' Property for dataset size '''\n",
    "        return len(self._src_insts) #数据集大小\n",
    "\n",
    "    @property\n",
    "    def src_vocab_size(self):\n",
    "        ''' Property for vocab size '''\n",
    "        return len(self._src_word2idx) #原文词汇集大小\n",
    "\n",
    "    @property\n",
    "    def src_word2idx(self):\n",
    "        ''' Property for word dictionary '''\n",
    "        return self._src_word2idx\n",
    "\n",
    "    @property\n",
    "    def tgt_word2idx(self):\n",
    "        ''' Property for word dictionary '''\n",
    "        return self._tgt_word2idx\n",
    "\n",
    "    @property\n",
    "    def src_idx2word(self):\n",
    "        ''' Property for index dictionary '''\n",
    "        return self._src_idx2word\n",
    "\n",
    "    @property\n",
    "    def tgt_idx2word(self):\n",
    "        ''' Property for index dictionary '''\n",
    "        return self._tgt_idx2word\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_insts\n",
    "\n",
    "    def __getitem__(self, idx): #按照index取语句 译文语句可能不存在\n",
    "        if self._tgt_insts:\n",
    "            return self._src_insts[idx], self._tgt_insts[idx]\n",
    "        return self._src_insts[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import copy\n",
    "import gc\n",
    "import math\n",
    "import tqdm\n",
    "import torch\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self, model_name: str, hidden: int, dropout: float) -> None:\n",
    "        super().__init__()\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        self.prediction_model = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(dropout),\n",
    "                torch.nn.Linear(self.transformer.config.hidden_size, hidden),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden, 1),\n",
    "            )\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, label: torch.Tensor, *args: torch.Tensor, **kwargs: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Feed all arguments to the transformer\n",
    "        transformer_output = self.transformer(*args, **kwargs)\n",
    "        # Get a fixed-size representation with mean pooling\n",
    "        intermediate: torch.Tensor = transformer_output.last_hidden_state.mean(1)\n",
    "        # Apply our MLP\n",
    "        output: torch.Tensor = self.prediction_model(intermediate)[:, 0]\n",
    "        # We feed the output without the sigmoid to the BCEWithLogitsLoss for numerical stability, and only use the prediction for debugging/metric computation\n",
    "        loss: torch.Tensor = self.loss(output, label.to(dtype=torch.float32))\n",
    "        prediction: torch.Tensor = torch.nn.functional.sigmoid(output)\n",
    "        return loss, prediction, transformer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, tokenizer, train_ds, dev_ds, test_ds, config):\n",
    "        self.config = config\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.prepare_data(train=train_ds, dev=dev_ds, test=test_ds)\n",
    "        self.prepare_model()\n",
    "\n",
    "    def prepare_data(self, **kwargs):\n",
    "        def tokenization(batched_text):\n",
    "            return self.tokenizer(batched_text['text'], padding='max_length', truncation=True, max_length=self.tokenizer.model_max_length)\n",
    "\n",
    "        self.dataset = {}\n",
    "        self.iterator = {}\n",
    "        for split in [\"train\", \"dev\", \"test\"]:\n",
    "            data = kwargs[split]\n",
    "            tokenized = data.map(tokenization,\n",
    "                                 batched=True,\n",
    "                                 batch_size=len(data),\n",
    "                                 remove_columns=['text'])\n",
    "            tokenized.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "            self.dataset[split] = tokenized\n",
    "            self.iterator[split] = lambda split=split, trainer=self: torch.utils.data.DataLoader(dataset=trainer.dataset[split],\n",
    "                                                                                                 batch_size=trainer.config[\"batch_size\"],\n",
    "                                                                                                 shuffle=True)\n",
    "\n",
    "    def prepare_model(self) -> None:\n",
    "        self.model = Model(self.config[\"model_name\"], self.config[\"hidden\"], self.config[\"dropout\"])\n",
    "        self.model.to(self.device)\n",
    "        self.optimizer = transformers.AdamW(self.model.parameters(),\n",
    "                                            lr=self.config[\"learning_rate\"],\n",
    "                                            weight_decay=self.config.get(\"weight_decay\", 0))\n",
    "        max_iterations: int = self.config[\"max_epoch\"]*self.config.get(\"batch_per_epoch\", len(self.dataset[\"train\"]))\n",
    "        # Decrease learning rate linearly\n",
    "        self.scheduler = transformers.get_linear_schedule_with_warmup(self.optimizer, self.config[\"warmup_step\"], max_iterations)\n",
    "        self.scaler = torch.cuda.amp.GradScaler()  # Used to scale gradients to avoid rounding to 0 when using float16\n",
    "\n",
    "    def eval(self, split: str) -> float:\n",
    "        with torch.no_grad():\n",
    "            # Accumulate gradient to better estimate it even with small batches\n",
    "            accuracy_accumulator = 0\n",
    "            num_samples = 0\n",
    "            self.model.eval()\n",
    "            for batch in self.iterator[split]():\n",
    "                batch = {key: value.to(self.device) for key, value in batch.items()}\n",
    "                with torch.cuda.amp.autocast():  # Use mixed-precision float16\n",
    "                    loss, prediction, transformer_output = self.model(**batch)\n",
    "                accuracy_accumulator += ((prediction > 0.5) == batch[\"label\"]).sum().item()\n",
    "                num_samples += batch[\"label\"].shape[0]\n",
    "            accuracy = accuracy_accumulator / num_samples\n",
    "            return accuracy\n",
    "      \n",
    "    def train_step(self) -> None:\n",
    "        \"\"\" Apply the gradients to the parameters. \"\"\"\n",
    "        self.scaler.unscale_(self.optimizer)  # Gradients are scaled in order to avoid rounding to 0 when casting to float16\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config[\"max_grad_norm\"])  # Clip to gradients to a maximum value (to be robust to outliers)\n",
    "        self.scaler.step(self.optimizer)  # Add the gradient to the parameters\n",
    "        self.scheduler.step()  # Update the learning rate\n",
    "        self.scaler.update()  # Update by how much the gradients should be scaled to avoid rounding to 0\n",
    "        self.optimizer.zero_grad()  # Set the gradients to 0 to prepare for the next iteration\n",
    "\n",
    "    def run(self) -> None:\n",
    "        loop = tqdm.trange(self.config[\"max_epoch\"], desc=\"Training\")\n",
    "        best_dev = -math.inf\n",
    "        best_dev_epoch = -math.inf\n",
    "        best_state_dict = None  # Used to save the best model\n",
    "        self.train_acc = []\n",
    "        self.dev_acc = []\n",
    "        for epoch in loop:\n",
    "            # Accumulate gradient to better estimate it even with small batches\n",
    "            accuracy_accumulator = 0\n",
    "            num_samples = 0\n",
    "            self.model.train()\n",
    "            for batch_id, batch in enumerate(self.iterator[\"train\"]()):\n",
    "                if batch_id >= self.config.get(\"batch_per_epoch\", math.inf):\n",
    "                    break\n",
    "                batch = {key: value.to(self.device) for key, value in batch.items()}  \n",
    "                with torch.cuda.amp.autocast():  # Use mixed-precision float16\n",
    "                    loss, prediction, transformer_output = self.model(**batch)\n",
    "                accuracy_accumulator += ((prediction > 0.5) == batch[\"label\"]).sum().item()\n",
    "                num_samples += batch[\"label\"].shape[0]\n",
    "                self.scaler.scale(loss).backward()  # Accumulate the (scaled) gradients\n",
    "                if (1+batch_id) % self.config.get(\"accumulation\", 1) == 0:\n",
    "                    self.train_step()\n",
    "            self.train_step()\n",
    "            accuracy = accuracy_accumulator / num_samples\n",
    "            dev = self.eval(\"dev\")\n",
    "            loop.set_postfix(epoch=f\"{epoch+1:3}\", DEV=f\"{dev:.4f}\", TRAIN=f\"{accuracy:.4f}\")\n",
    "            self.train_acc.append(accuracy)\n",
    "            self.dev_acc.append(dev)\n",
    "            if dev > best_dev:  # If dev score improved\n",
    "                best_dev = dev\n",
    "                best_dev_epoch = epoch\n",
    "                best_state_dict = copy.deepcopy(self.model.state_dict())  # Save the weights of the model\n",
    "            elif epoch - best_dev_epoch > self.config.get(\"patience\", 0):  # If dev score worsened for several steps (or 1 if patience is 0)\n",
    "                break # Early stopping\n",
    "        if best_state_dict is not None:  # If we improved over random initialization\n",
    "            self.model.load_state_dict(best_state_dict)  # Load the model with the best dev score\n",
    "        for split in [\"train\", \"dev\", \"test\"]:\n",
    "            print(f\"Accuracy on {split} split: {self.eval(split)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Get 1254 instances from sums.json\n"
     ]
    }
   ],
   "source": [
    "train_ds_pre_df, dev_ds_pre_df, test_ds_pre_df = read_data(\n",
    "    'sums.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_ds_pre_df['text'].isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_pre_df.to_csv(\"data_file_pre/train.csv\", index=False)\n",
    "dev_ds_pre_df.to_csv(\"data_file_pre/dev.csv\", index=False)\n",
    "test_ds_pre_df.to_csv(\"data_file_pre/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration data_file_pre-f04bcf91d7bc917b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/data_file_pre to /Users/meteor/.cache/huggingface/datasets/csv/data_file_pre-f04bcf91d7bc917b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3192.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 480.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /Users/meteor/.cache/huggingface/datasets/csv/data_file_pre-f04bcf91d7bc917b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 555.05it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\": \"train.csv\", \"dev\": \"dev.csv\", \"test\": \"test.csv\"}\n",
    "dataset_pre = load_dataset('data_file_pre', data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = dataset_pre['train'].shuffle(seed=42)#.select(range(100))\n",
    "dev_ds = dataset_pre['dev'].shuffle(seed=42)#.select(range(100))\n",
    "test_ds = dataset_pre['test'].shuffle(seed=42)#.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.93ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.07ba/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.61ba/s]\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/Users/meteor/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "Training:   0%|          | 0/50 [00:00<?, ?it/s]/Users/meteor/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "/Users/meteor/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Training:   6%|▌         | 3/50 [2:56:19<46:02:32, 3526.65s/it, DEV=0.5124, TRAIN=0.5686, epoch=3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_55056/467647751.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_55056/109561696.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Use mixed-precision float16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0maccuracy_accumulator\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mnum_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_55056/1164257281.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, label, *args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Feed all arguments to the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Get a fixed-size representation with mean pooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mintermediate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             )\n\u001b[1;32m    330\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "trainer_config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"accumulation\": 16,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"batch_per_epoch\": 80,\n",
    "    \"max_epoch\": 50,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"hidden\": 256,  # Size of the hidden layer of the MLP.\n",
    "    \"dropout\": 0,  # dropout of the transformers' output, before the MLP.\n",
    "    \"patience\": 5,  # If the dev score worsen 3 epoch in a row, stop the training.\n",
    "    \"warmup_step\": 20,\n",
    "\n",
    "}\n",
    "\n",
    "model = \"distilbert-base-uncased\"\n",
    "trainer_config[\"model_name\"] = model\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)\n",
    "trainer = Trainer(tokenizer, train_ds, dev_ds, test_ds, trainer_config)\n",
    "trainer.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class PredictDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data_file, test_size, max_len, tokenizer):\n",
    "        self.max_len = max_len # use to padding all sequence to a fixed length\n",
    "        self.tokenizer = tokenizer\n",
    "        with open(data_file, 'r') as fp:\n",
    "            data = json.load(fp)\n",
    "        \n",
    "        self.data = []\n",
    "        for data_dict in data:\n",
    "            s = data_dict['speech'][-1]\n",
    "            if s['ECB']:\n",
    "                l = s['ECB'][0].strip()\n",
    "            else:\n",
    "                l = s['FED'][0].strip()\n",
    "            #words = l.split(' ')\n",
    "            text_token = self.tokenizer(l, padding='max_length', truncation=True, max_length=self.max_len)\n",
    "            #print(text_token)\n",
    "\n",
    "            text = torch.tensor(text_token['input_ids'], dtype=float)\n",
    "            text_att = torch.tensor(text_token['attention_mask'], dtype=int)\n",
    "            stock = torch.tensor(data_dict['stock'], dtype=float)\n",
    "            tgt_c = torch.tensor(data_dict['target_classif'], dtype=int)\n",
    "            tgt_r = torch.tensor(data_dict['target_reg'], dtype=float)\n",
    "\n",
    "            \n",
    "            self.data.append({'text_token':text, 'text_att':text_att, 'stock':stock, 'target_classif':tgt_c, 'target_reg':tgt_r})\n",
    "    \n",
    "\n",
    "        self.train_data, self.test_data = train_test_split(self.data, test_size=test_size,random_state=0)\n",
    "        print(\"=\"*50)\n",
    "        print(\"Data Preprocess Done!\")\n",
    "        print(\"Dataset size:{}, train:{}, val:{}\".\n",
    "              format(len(self.data),len(self.train_data),len(self.test_data)))\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.data[item]\n",
    "\n",
    "    def train_set(self):\n",
    "        '''call this method to switch to train mode'''\n",
    "        self.data = self.train_data\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def test_set(self):\n",
    "        '''call this method to switch to test mode'''\n",
    "        self.data = self.test_data\n",
    "        return copy.deepcopy(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Data Preprocess Done!\n",
      "Dataset size:1254, train:1003, val:251\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "model = \"distilbert-base-uncased\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "dataset = PredictDataset('sums.json', 0.2, 512, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Generator\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name, dropout=0.5, fine_tune=True):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.transformer = transformers.AutoModel.from_pretrained(model_name)\n",
    "        #self.output_size = output_size\n",
    "\n",
    "        if fine_tune:\n",
    "            self.fine_tune()\n",
    "\n",
    "    def forward(self, speech_text):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        :param images: images, a tensor of dimensions (batch_size, 3, image_size, image_size)\n",
    "        :return: encoded images\n",
    "        \"\"\"\n",
    "        out = self.transformer(speech_text)  # (batch_size, transformer_output_size)\n",
    "        out = out.last_hidden_state.mean(1)\n",
    "        #out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 1)\n",
    "        return out\n",
    "\n",
    "    def fine_tune(self, fine_tune=True):\n",
    "        \"\"\"\n",
    "        Allow or prevent the computation of gradients for convolutional blocks 2 through 4 of the encoder.\n",
    "\n",
    "        :param fine_tune: Allow?\n",
    "        \"\"\"\n",
    "        for p in self.transformer.parameters():\n",
    "            p.requires_grad = False\n",
    "        # If fine-tuning, only fine-tune convolutional blocks 2 through 4\n",
    "        for c in list(self.transformer.children())[5:]:\n",
    "            for p in c.parameters():\n",
    "                p.requires_grad = fine_tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder_Classif(nn.Module):\n",
    "    def __init__(self, stock_data_size, input_size, encoded_size, hidden_size, dropout=0.5):\n",
    "        \"\"\"\n",
    "        :param encoder_dim: feature size of encoded images\n",
    "        :param decoder_dim: size of decoder's RNN\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.encoded_size = encoded_size \n",
    "        self.stock_data_size = stock_data_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.encoder = torch.nn.Linear(input_size, encoded_size)\n",
    "\n",
    "        self.network = torch.nn.Sequential(\n",
    "                torch.nn.Dropout(self.dropout),\n",
    "                torch.nn.Linear(encoded_size + stock_data_size, hidden_size),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_size, 1),\n",
    "            )\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        #self.init_weights()\n",
    "\n",
    "    def forward(self, input, stock_price):\n",
    "        \"\"\"\n",
    "        Forward propagation.\n",
    "\n",
    "        :param input: encoded speech text, the output of the Encoder\n",
    "        :param stock_price: the stock price        \n",
    "        :return: classification prob\n",
    "        \"\"\"\n",
    "\n",
    "        encoded_output = self.encoder(input)\n",
    "        merged_data = torch.cat([encoded_output, stock_price],dim=1)\n",
    "        out = self.network(merged_data)\n",
    "        p = self.sigmoid(out)\n",
    "\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Keeps track of most recent, average, sum, and count of a metric.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "def clip_gradient(optimizer, grad_clip):\n",
    "    \"\"\"\n",
    "    Clips gradients computed during backpropagation to avoid explosion of gradients.\n",
    "\n",
    "    :param optimizer: optimizer with the gradients to be clipped\n",
    "    :param grad_clip: clip value\n",
    "    \"\"\"\n",
    "    for group in optimizer.param_groups:\n",
    "        for param in group['params']:\n",
    "            if param.grad is not None:\n",
    "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
    "\n",
    "def adjust_learning_rate(optimizer, shrink_factor):\n",
    "    \"\"\"\n",
    "    Shrinks learning rate by a specified factor.\n",
    "\n",
    "    :param optimizer: optimizer whose learning rate must be shrunk.\n",
    "    :param shrink_factor: factor in interval (0, 1) to multiply learning rate with.\n",
    "    \"\"\"\n",
    "    print(\"\\nDECAYING learning rate.\")\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * shrink_factor\n",
    "    print(\"The new learning rate is %f\\n\" % (optimizer.param_groups[0]['lr'],))\n",
    "\n",
    "def save_checkpoint(save_dir, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer, decoder_optimizer,\n",
    "                    loss, is_best):\n",
    "    \"\"\"\n",
    "    Saves model checkpoint.\n",
    "    :param save_dir: store checkpoints here\n",
    "    :param epoch: epoch number\n",
    "    :param epochs_since_improvement: number of epochs since last improvement in BLEU-4 score\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights, if fine-tuning\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param loss: validation loss score for this epoch\n",
    "    :param is_best: is this checkpoint the best so far?\n",
    "    \"\"\"\n",
    "    state = {'epoch': epoch,\n",
    "             'epochs_since_improvement': epochs_since_improvement,\n",
    "             'testLoss': loss,\n",
    "             'encoder': encoder,\n",
    "             'decoder': decoder,\n",
    "             'encoder_optimizer': encoder_optimizer,\n",
    "             'decoder_optimizer': decoder_optimizer}\n",
    "    filename = save_dir +'checkpoint_' + 'epoch_' + str(epoch) + '_loss:{:.2f}'.format(loss) + '.pth'\n",
    "    torch.save(state, filename)\n",
    "    # If this checkpoint is the best so far, store a copy so it doesn't get overwritten by a worse checkpoint\n",
    "    if is_best:\n",
    "        filename = save_dir +'checkpoint_' + 'best.pth'\n",
    "        torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.utils.data as Data\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "print_freq = 1  # print training/validation stats every __ batches\n",
    "\n",
    "def train_classif(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch):\n",
    "    \"\"\"\n",
    "    Performs one epoch's training.\n",
    "\n",
    "    :param train_loader: DataLoader for training data\n",
    "    :param encoder: encoder model\n",
    "    :param decoder: decoder model\n",
    "    :param criterion: loss layer\n",
    "    :param encoder_optimizer: optimizer to update encoder's weights (if fine-tuning)\n",
    "    :param decoder_optimizer: optimizer to update decoder's weights\n",
    "    :param epoch: epoch number\n",
    "    \"\"\"\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        text = data['text_token'].type(torch.IntTensor)\n",
    "        stock_price = data['stock'].type(torch.FloatTensor)\n",
    "        label = data['target_classif'].type(torch.FloatTensor)\n",
    "\n",
    "        # Forward prop.\n",
    "        decoder_input = encoder(text)\n",
    "        label_pred = decoder(decoder_input, stock_price).reshape(-1)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(label_pred, label)\n",
    "\n",
    "        # Back prop.\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip gradients\n",
    "        if grad_clip is not None:\n",
    "            clip_gradient(decoder_optimizer, grad_clip)\n",
    "            if encoder_optimizer is not None:\n",
    "                clip_gradient(encoder_optimizer, grad_clip)\n",
    "\n",
    "        # Update weights\n",
    "        decoder_optimizer.step()\n",
    "        if encoder_optimizer is not None:\n",
    "            encoder_optimizer.step()\n",
    "\n",
    "        # Keep track of metric\n",
    "        losses.update(loss.item())\n",
    "        batch_time.update(time.time() - start)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        # Print status\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}] [{1}/{2}]\\n'\n",
    "                  'Batch Time {batch_time.val:.3f}s (Average:{batch_time.avg:.3f}s)\\n'\n",
    "                  'Data Load Time {data_time.val:.3f}s (Average:{data_time.avg:.3f}s)\\n'\n",
    "                  'Loss {loss.val:.4f} (Average:{loss.avg:.4f})\\n'.format(epoch, i, len(train_loader),\n",
    "                                                                          batch_time=batch_time,\n",
    "                                                                          data_time=data_time, loss=losses))\n",
    "\n",
    "\n",
    "def validate(val_loader, encoder, decoder, criterion):\n",
    "\n",
    "    decoder.eval()  # eval mode (no dropout or batchnorm)\n",
    "    if encoder is not None:\n",
    "        encoder.eval()\n",
    "\n",
    "    batch_time = AverageMeter()  # forward prop. + back prop. time\n",
    "    data_time = AverageMeter()  # data loading time\n",
    "    losses = AverageMeter()  # loss\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # explicitly disable gradient calculation to avoid CUDA memory error\n",
    "    with torch.no_grad():\n",
    "        accuracy_accumulator = 0\n",
    "        num_samples = 0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            text = data['text_token'].type(torch.IntTensor)\n",
    "            stock_price = data['stock'].type(torch.FloatTensor)\n",
    "            label = data['target_classif'].type(torch.FloatTensor)\n",
    "\n",
    "            # Forward prop.\n",
    "            decoder_input = encoder(text)\n",
    "            label_pred = decoder(decoder_input, stock_price).reshape(-1)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(label_pred, label)\n",
    "\n",
    "            # Keep track of metrics\n",
    "            losses.update(loss.item())\n",
    "            batch_time.update(time.time() - start)\n",
    "\n",
    "            start = time.time()\n",
    "            accuracy_accumulator += ((label_pred > 0.5) == label).sum().item()\n",
    "            num_samples += label.shape[0]\n",
    "\n",
    "            print(accuracy_accumulator)\n",
    "            print(num_samples)\n",
    "\n",
    "            if i % print_freq == 0:\n",
    "                print('Validation: [{0}/{1}]\\n'\n",
    "                        'Batch Time {batch_time.val:.3f}s (Average:{batch_time.avg:.3f}s)\\n'\n",
    "                        'Loss {loss.val:.4f} (Average:{loss.avg:.4f})\\n'.format(i, len(val_loader), batch_time=batch_time,loss=losses))\n",
    "        \n",
    "        accuracy = accuracy_accumulator / num_samples\n",
    "\n",
    "    return losses.avg, label, label_pred, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # sets device for model and PyTorch tensors\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "\n",
    "model = \"distilbert-base-uncased\"\n",
    "\n",
    "data_path = 'sums.json'\n",
    "stock_data_size = 20\n",
    "input_size = 768\n",
    "encoded_size = 20 \n",
    "hidden_size = 64\n",
    "dropout = 0.5\n",
    "\n",
    "start_epoch = 1\n",
    "epochs = 20  # number of epochs to train for (if early stopping is not triggered)\n",
    "epochs_since_improvement = 0  # keeps track of number of epochs since there's been an improvement\n",
    "batch_size = 32\n",
    "workers = 1  # for data-loading; right now, only 1 works with h5py\n",
    "encoder_lr = 1e-4  # learning rate for encoder if fine-tuning\n",
    "decoder_lr = 4e-4  # learning rate for decoder\n",
    "grad_clip = 5.  # clip gradients at an absolute value of\n",
    "alpha_c = 1.  # regularization parameter for 'doubly stochastic attention', as in the paper\n",
    "best_loss = 1.  # best loss score right now\n",
    "print_freq = 8  # print training/validation stats every __ batches\n",
    "fine_tune_encoder = False # fine-tune encoder?\n",
    "checkpoint = None  # path to checkpoint, None if none\n",
    "save_path = './checkpoint/' # checkpoint save path\n",
    "\n",
    "#max_len = 15 # the longest sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Data Preprocess Done!\n",
      "Dataset size:1254, train:1003, val:251\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if checkpoint is None:\n",
    "    decoder = Decoder_Classif(stock_data_size=stock_data_size, input_size=input_size, encoded_size=encoded_size, hidden_size=hidden_size)\n",
    "    decoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, decoder.parameters()),\n",
    "                                        lr=decoder_lr)\n",
    "    encoder = Encoder(model)\n",
    "    encoder.fine_tune(fine_tune_encoder)\n",
    "    encoder_optimizer = torch.optim.Adam(params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "                                        lr=encoder_lr) if fine_tune_encoder else None\n",
    "\n",
    "else:\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    epochs_since_improvement = checkpoint['epochs_since_improvement']\n",
    "    best_loss = checkpoint['testLoss']\n",
    "    decoder = checkpoint['decoder']\n",
    "    decoder_optimizer = checkpoint['decoder_optimizer']\n",
    "    encoder = checkpoint['encoder']\n",
    "    encoder_optimizer = checkpoint['encoder_optimizer']\n",
    "    if fine_tune_encoder is True and encoder_optimizer is None:\n",
    "        encoder.fine_tune(fine_tune_encoder)\n",
    "        encoder_optimizer = torch.optim.Adam(\n",
    "            params=filter(lambda p: p.requires_grad, encoder.parameters()),\n",
    "            lr=encoder_lr)\n",
    "\n",
    "decoder = decoder.to(device)\n",
    "encoder = encoder.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)\n",
    "dataset = PredictDataset(data_file=data_path, test_size=0.2, max_len=512, tokenizer=tokenizer)\n",
    "train_loader = Data.DataLoader(dataset.train_set(), batch_size=batch_size, shuffle=False)\n",
    "val_loader = Data.DataLoader(dataset.test_set(), batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1] [0/32]\n",
      "Batch Time 31.924s (Average:31.924s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7337 (Average:0.7337)\n",
      "\n",
      "Epoch: [1] [1/32]\n",
      "Batch Time 25.804s (Average:28.864s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7639 (Average:0.7488)\n",
      "\n",
      "Epoch: [1] [2/32]\n",
      "Batch Time 27.389s (Average:28.372s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7566 (Average:0.7514)\n",
      "\n",
      "Epoch: [1] [3/32]\n",
      "Batch Time 26.142s (Average:27.815s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7297 (Average:0.7460)\n",
      "\n",
      "Epoch: [1] [4/32]\n",
      "Batch Time 27.230s (Average:27.698s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7648 (Average:0.7497)\n",
      "\n",
      "Epoch: [1] [5/32]\n",
      "Batch Time 26.931s (Average:27.570s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6998 (Average:0.7414)\n",
      "\n",
      "Epoch: [1] [6/32]\n",
      "Batch Time 26.574s (Average:27.428s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7645 (Average:0.7447)\n",
      "\n",
      "Epoch: [1] [7/32]\n",
      "Batch Time 25.488s (Average:27.185s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7536 (Average:0.7458)\n",
      "\n",
      "Epoch: [1] [8/32]\n",
      "Batch Time 25.880s (Average:27.040s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7536 (Average:0.7467)\n",
      "\n",
      "Epoch: [1] [9/32]\n",
      "Batch Time 25.485s (Average:26.885s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7306 (Average:0.7451)\n",
      "\n",
      "Epoch: [1] [10/32]\n",
      "Batch Time 27.744s (Average:26.963s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7227 (Average:0.7430)\n",
      "\n",
      "Epoch: [1] [11/32]\n",
      "Batch Time 24.370s (Average:26.747s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7291 (Average:0.7419)\n",
      "\n",
      "Epoch: [1] [12/32]\n",
      "Batch Time 23.415s (Average:26.491s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7710 (Average:0.7441)\n",
      "\n",
      "Epoch: [1] [13/32]\n",
      "Batch Time 23.448s (Average:26.273s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7244 (Average:0.7427)\n",
      "\n",
      "Epoch: [1] [14/32]\n",
      "Batch Time 23.333s (Average:26.077s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7245 (Average:0.7415)\n",
      "\n",
      "Epoch: [1] [15/32]\n",
      "Batch Time 23.669s (Average:25.927s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7116 (Average:0.7396)\n",
      "\n",
      "Epoch: [1] [16/32]\n",
      "Batch Time 24.218s (Average:25.826s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6923 (Average:0.7369)\n",
      "\n",
      "Epoch: [1] [17/32]\n",
      "Batch Time 23.905s (Average:25.720s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7323 (Average:0.7366)\n",
      "\n",
      "Epoch: [1] [18/32]\n",
      "Batch Time 24.756s (Average:25.669s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7170 (Average:0.7356)\n",
      "\n",
      "Epoch: [1] [19/32]\n",
      "Batch Time 23.657s (Average:25.568s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7184 (Average:0.7347)\n",
      "\n",
      "Epoch: [1] [20/32]\n",
      "Batch Time 23.690s (Average:25.479s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7231 (Average:0.7342)\n",
      "\n",
      "Epoch: [1] [21/32]\n",
      "Batch Time 23.798s (Average:25.402s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7701 (Average:0.7358)\n",
      "\n",
      "Epoch: [1] [22/32]\n",
      "Batch Time 23.757s (Average:25.331s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6952 (Average:0.7340)\n",
      "\n",
      "Epoch: [1] [23/32]\n",
      "Batch Time 26.303s (Average:25.371s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7361 (Average:0.7341)\n",
      "\n",
      "Epoch: [1] [24/32]\n",
      "Batch Time 25.762s (Average:25.387s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7759 (Average:0.7358)\n",
      "\n",
      "Epoch: [1] [25/32]\n",
      "Batch Time 22.339s (Average:25.270s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6828 (Average:0.7338)\n",
      "\n",
      "Epoch: [1] [26/32]\n",
      "Batch Time 22.351s (Average:25.162s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6786 (Average:0.7317)\n",
      "\n",
      "Epoch: [1] [27/32]\n",
      "Batch Time 22.710s (Average:25.074s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7292 (Average:0.7316)\n",
      "\n",
      "Epoch: [1] [28/32]\n",
      "Batch Time 22.601s (Average:24.989s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7423 (Average:0.7320)\n",
      "\n",
      "Epoch: [1] [29/32]\n",
      "Batch Time 22.225s (Average:24.897s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7068 (Average:0.7312)\n",
      "\n",
      "Epoch: [1] [30/32]\n",
      "Batch Time 28.553s (Average:25.015s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7412 (Average:0.7315)\n",
      "\n",
      "Epoch: [1] [31/32]\n",
      "Batch Time 7.714s (Average:24.474s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7145 (Average:0.7309)\n",
      "\n",
      "Validation: [0/8]\n",
      "Batch Time 20.513s (Average:20.513s)\n",
      "Loss 0.6922 (Average:0.6922)\n",
      "\n",
      "Validation: [1/8]\n",
      "Batch Time 19.505s (Average:20.009s)\n",
      "Loss 0.7148 (Average:0.7035)\n",
      "\n",
      "Validation: [2/8]\n",
      "Batch Time 19.497s (Average:19.839s)\n",
      "Loss 0.6841 (Average:0.6971)\n",
      "\n",
      "Validation: [3/8]\n",
      "Batch Time 19.628s (Average:19.786s)\n",
      "Loss 0.7041 (Average:0.6988)\n",
      "\n",
      "Validation: [4/8]\n",
      "Batch Time 19.385s (Average:19.706s)\n",
      "Loss 0.6783 (Average:0.6947)\n",
      "\n",
      "Validation: [5/8]\n",
      "Batch Time 19.697s (Average:19.704s)\n",
      "Loss 0.6845 (Average:0.6930)\n",
      "\n",
      "Validation: [6/8]\n",
      "Batch Time 19.431s (Average:19.665s)\n",
      "Loss 0.6876 (Average:0.6923)\n",
      "\n",
      "Validation: [7/8]\n",
      "Batch Time 16.417s (Average:19.259s)\n",
      "Loss 0.7164 (Average:0.6953)\n",
      "\n",
      "Validation: Epoch [1/20]\n",
      "Loss 0.6953\n",
      "Accuracy 15.7251\n",
      "\n",
      "Epoch: [2] [0/32]\n",
      "Batch Time 24.644s (Average:24.644s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7126 (Average:0.7126)\n",
      "\n",
      "Epoch: [2] [1/32]\n",
      "Batch Time 22.523s (Average:23.583s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7155 (Average:0.7140)\n",
      "\n",
      "Epoch: [2] [2/32]\n",
      "Batch Time 22.861s (Average:23.342s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7197 (Average:0.7159)\n",
      "\n",
      "Epoch: [2] [3/32]\n",
      "Batch Time 23.190s (Average:23.304s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7086 (Average:0.7141)\n",
      "\n",
      "Epoch: [2] [4/32]\n",
      "Batch Time 22.865s (Average:23.216s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7100 (Average:0.7133)\n",
      "\n",
      "Epoch: [2] [5/32]\n",
      "Batch Time 22.866s (Average:23.158s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.6952 (Average:0.7103)\n",
      "\n",
      "Epoch: [2] [6/32]\n",
      "Batch Time 22.559s (Average:23.073s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7162 (Average:0.7111)\n",
      "\n",
      "Epoch: [2] [7/32]\n",
      "Batch Time 23.339s (Average:23.106s)\n",
      "Data Load Time 0.000s (Average:0.000s)\n",
      "Loss 0.7059 (Average:0.7105)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_79730/588881173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             epoch=epoch)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# One epoch's validation, return the average loss of each batch in this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_79730/1897376320.py\u001b[0m in \u001b[0;36mtrain_classif\u001b[0;34m(train_loader, encoder, decoder, criterion, encoder_optimizer, decoder_optimizer, epoch)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Forward prop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mlabel_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstock_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/jn/zyqg1tvd3_x4k42nr8p6yr100000gn/T/ipykernel_79730/2826393861.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, speech_text)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencoded\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \"\"\"\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (batch_size, transformer_output_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_hidden_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#out = out.permute(0, 2, 3, 1)  # (batch_size, encoded_image_size, encoded_image_size, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         )\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m             )\n\u001b[1;32m    330\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# Feed Forward Network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         \u001b[0mffn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mffn_output\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msa_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, seq_length, dim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_chunking_to_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mff_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   2328\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mff_chunk\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/bike-ramp/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + epochs):\n",
    "\n",
    "    # Decay learning rate if there is no improvement for 8 consecutive epochs, and terminate training after 20\n",
    "    if epochs_since_improvement == 20:\n",
    "        break\n",
    "    if epochs_since_improvement > 0 and epochs_since_improvement % 8 == 0:\n",
    "        adjust_learning_rate(decoder_optimizer, 0.8)\n",
    "        if fine_tune_encoder:\n",
    "            adjust_learning_rate(encoder_optimizer, 0.8)\n",
    "\n",
    "    # One epoch's training\n",
    "    train_classif(train_loader=train_loader,\n",
    "            encoder=encoder,\n",
    "            decoder=decoder,\n",
    "            criterion=criterion,\n",
    "            encoder_optimizer=encoder_optimizer,\n",
    "            decoder_optimizer=decoder_optimizer,\n",
    "            epoch=epoch)\n",
    "\n",
    "    # One epoch's validation, return the average loss of each batch in this epoch\n",
    "    loss, label, label_pred, acc = validate(val_loader=val_loader,\n",
    "                                encoder=encoder, decoder=decoder, criterion=criterion)\n",
    "    \n",
    "    print('Validation: Epoch [{0}/{1}]\\n'\n",
    "                        'Loss {loss:.4f}\\n'\n",
    "                        'Accuracy {acc:.4f}\\n'.format(epoch, epochs, loss=loss, acc=acc))\n",
    "\n",
    "\n",
    "    # Check if there was an improvement\n",
    "    is_best = loss < best_loss\n",
    "    best_loss = min(loss, best_loss)\n",
    "    if not is_best:\n",
    "        epochs_since_improvement += 1\n",
    "        print(\"\\nEpochs since last improvement: %d\\n\" % (epochs_since_improvement,))\n",
    "    else:\n",
    "        epochs_since_improvement = 0\n",
    "\n",
    "    # Save checkpoint\n",
    "    save_checkpoint(save_path, epoch, epochs_since_improvement, encoder, decoder, encoder_optimizer,\n",
    "                    decoder_optimizer, loss, is_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "808b2d6506002d59e33c894cd39ce65ecb585cca6d5df7e47a6227f88953c98f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('bike-ramp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
